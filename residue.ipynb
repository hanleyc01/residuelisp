{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Residue Hyperdimensional Computing\n",
    "\n",
    "In this notebook we implement Kymn et al. (2023), \n",
    "[*Computing with Residue Numbers in High-Dimensional Representation*](https://arxiv.org/abs/2311.04872)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from vsa.vocabulary import Vocabulary\n",
    "from typing import Dict, List, Tuple, Literal\n",
    "import math\n",
    "import cmath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RHC(Vocabulary):\n",
    "    \"\"\"\n",
    "    Residue Hyperdimensional Computing.\n",
    "\n",
    "    Attributes:\n",
    "        dim: An integer representing the dimensionality of the vectors produced.\n",
    "        symbols: An optional dictionary mapping labels to symbols.\n",
    "        moduli: A list of integers which are the moduli of the encoding scheme.\n",
    "    \"\"\"\n",
    "\n",
    "    _dim: int\n",
    "    _symbols: Dict[str, np.ndarray]\n",
    "    _moduli: List[int]\n",
    "    _roots: Dict[int, np.ndarray]\n",
    "    _phis: Dict[int, np.ndarray]\n",
    "\n",
    "    # dictionary mapping each moduli m_i to an m_i x self.dim matrix,\n",
    "    # used for residue decoding\n",
    "    _codebook: Dict[int, np.ndarray]\n",
    "\n",
    "    def __init__(\n",
    "        self, dim: int, moduli: List[int], symbols: Dict[str, np.ndarray] = {}\n",
    "    ) -> None:\n",
    "        self._dim = dim\n",
    "        self._symbols = symbols\n",
    "        self._moduli = moduli\n",
    "        self.__post_init__()\n",
    "\n",
    "    def __post_init__(self) -> None:\n",
    "        self._roots, self._phis = self._get_phis()\n",
    "\n",
    "        for key, value in self._phis.items():\n",
    "            self._symbols[str(key)] = value\n",
    "\n",
    "        self._invs = self._get_invs()\n",
    "\n",
    "        self._codebook = {}\n",
    "        for modulus in self.moduli:\n",
    "            modbook = np.zeros((modulus, self.dim), dtype=complex)\n",
    "            for i in range(modulus):\n",
    "                modbook[i, :] = self._phis[modulus] ** (i + 1)\n",
    "\n",
    "            self._codebook[modulus] = modbook.T\n",
    "\n",
    "    @property\n",
    "    def dim(self) -> int:\n",
    "        \"\"\"\n",
    "        The dimensionality of the RHC.\n",
    "        \"\"\"\n",
    "        return self._dim\n",
    "\n",
    "    @property\n",
    "    def symbols(self) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"\n",
    "        The set of symbols and their values.\n",
    "        \"\"\"\n",
    "        return self._symbols\n",
    "\n",
    "    @property\n",
    "    def moduli(self) -> List[int]:\n",
    "        \"\"\"\n",
    "        The moduli of the RHC.\n",
    "        \"\"\"\n",
    "        return self._moduli\n",
    "\n",
    "    def _get_phis(self) -> Tuple[Dict[int, np.ndarray], Dict[int, np.ndarray]]:\n",
    "        \"\"\"\n",
    "        For each modulus `m`, sample from the `m`-th roots of unity to\n",
    "        produce an `self.dim`-dimensional vector.\n",
    "\n",
    "        Returns:\n",
    "            A tuple of a dictionary mapping moduli to their real roots of unity,\n",
    "            and a dictionary mapping moduli to the complex angle roots of unity.\n",
    "        \"\"\"\n",
    "\n",
    "        real_phis = {}\n",
    "        phis = {}\n",
    "        for modulus in self.moduli:\n",
    "            real_phis[modulus] = self._roots_of_unity(modulus)\n",
    "            phis[modulus] = np.exp(cmath.sqrt(-1) * real_phis[modulus])\n",
    "        return real_phis, phis\n",
    "\n",
    "    def _roots_of_unity(self, modulus: int) -> np.ndarray:\n",
    "        \"\"\"Sample from the `modulus` roots of unity to create a\n",
    "            `self.dim`-dimensional vector.\n",
    "\n",
    "        Args:\n",
    "            modulus: An integer `m` to sample from the `m`th roots of unity.\n",
    "\n",
    "        Returns:\n",
    "            A real vector of sampled elements from the `modulus` roots of unity.\n",
    "        \"\"\"\n",
    "\n",
    "        # generate the `modulus`-roots of unity of the unit circle\n",
    "        roots = [2 * math.pi]\n",
    "        incr = (2 * math.pi) / modulus\n",
    "        curr = incr\n",
    "        while curr < 2 * math.pi:\n",
    "            roots.append(curr)\n",
    "            curr += incr\n",
    "\n",
    "        # create a vector of angles sampled from the `modulus`-roots of unity\n",
    "        sample_roots = np.vectorize(lambda _: np.random.choice(roots))\n",
    "        angles = sample_roots(np.zeros(self.dim))\n",
    "        return angles\n",
    "\n",
    "    def _get_invs(self) -> Dict[int, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Anti-base vectors for each moduli defined by the modular\n",
    "        multiplicative inverses of the real angles.\n",
    "\n",
    "        Returns:\n",
    "            A dictionary with the moduli as the keys and the inverses\n",
    "            of their associated vectors as values.\n",
    "        \"\"\"\n",
    "        # Implementation is ripped from `inverse_phases` function by Kymn\n",
    "        invs = {}\n",
    "        for modulus, roots in self._roots.items():\n",
    "            inv = np.zeros_like(roots)\n",
    "            for i in range(roots.size):\n",
    "                if np.round(np.angle(roots[i])).astype(int) == 0:\n",
    "                    inv[i] = 0\n",
    "                else:\n",
    "                    spin = int(np.round(np.angle(roots[i]) * modulus))\n",
    "                    inv[i] = pow(int(np.round(roots[i])), -1, modulus)\n",
    "            invs[modulus] = inv\n",
    "        return invs\n",
    "\n",
    "    def bind(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Bind two `RHC` vectors to create a new, orthogonal vector.\n",
    "\n",
    "        Returns:\n",
    "            A new `self.dim`-dimensional vector.\n",
    "        \"\"\"\n",
    "        return np.multiply(x, y)\n",
    "\n",
    "    def superpose(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Put vectors `x` and `y` into superposition.\n",
    "\n",
    "        Returns:\n",
    "            A new `self.dim`-dimensional vector.\n",
    "        \"\"\"\n",
    "        return x + y\n",
    "\n",
    "    def inv(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Invert a `self.dim`-dimensional vector.\n",
    "\n",
    "        Returns:\n",
    "            A new `self.dim`-dimensional vector which is the conjugate of `x`.\n",
    "        \"\"\"\n",
    "        return np.conjugate(x)\n",
    "\n",
    "    def add(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Add two encoded integers, or: `x (n_1) * x (n_2) = x (n_1 + n_2)`\n",
    "\n",
    "        Returns:\n",
    "            A new complex `np.ndarray` which satisfies the above property.\n",
    "        \"\"\"\n",
    "        return self.bind(x, y)\n",
    "\n",
    "    def _resonator_mul(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Implement multiplicative binding by decoding `y` into an integer,\n",
    "        and then performing element-wise exponentiation.\n",
    "\n",
    "        Returns:\n",
    "            A new complex `np.ndarray`.\n",
    "        \"\"\"\n",
    "        y_n = self.decode(y)\n",
    "        return np.pow(x, y)\n",
    "\n",
    "    def _kymn_mul(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Implement Kymn's method for multiplicative binding, which requires\n",
    "        calling a resonator network to recover the base vectors of `x`\n",
    "        and `y`, and then using the anti-base vector for each to\n",
    "        perform multiplicative binding.\n",
    "\n",
    "        Returns:\n",
    "            A new complex `np.ndarray`.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"TODO\")\n",
    "\n",
    "    def mul(\n",
    "        self,\n",
    "        x: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        decoder_method: Literal[\"decode\", \"kymn\"] = \"decode\",\n",
    "    ) -> np.ndarray:\n",
    "        if decoder_method == \"decode\":\n",
    "            return self._resonator_mul(x, y)\n",
    "        elif decoder_method == \"kymn\":\n",
    "            return self._kymn_mul(x, y)\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected decoder variant\", decoder_method)\n",
    "\n",
    "    def sub(self, x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Subtract two encoded integers.\n",
    "        \"\"\"\n",
    "        return self.add(x, self.inv(y))\n",
    "\n",
    "    def div(\n",
    "        self,\n",
    "        x: np.ndarray,\n",
    "        y: np.ndarray,\n",
    "        decoder_method: Literal[\"decode\", \"kymn\"] = \"decode\",\n",
    "    ) -> np.ndarray:\n",
    "        raise NotImplementedError(\"TODO\")\n",
    "\n",
    "    def sim(self, x: np.ndarray, y: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: A `self.dim`-dimensional vector.\n",
    "            y: A `self.dim`-dimensional vector.\n",
    "\n",
    "        Returns:\n",
    "            A float in `[-1, 1]` measuring the similarity between the two\n",
    "                vectors. `0` if orthogonal, `-1, 1` if related.\n",
    "        \"\"\"\n",
    "\n",
    "        return np.dot(x, np.conjugate(y.T)).real / self.dim\n",
    "\n",
    "    def encode(self, n: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Encode integer `n` into an RHC vector which is the Hadamard product\n",
    "        of each the moduli vectors exponentiated to `n`.\n",
    "\n",
    "        Returns:\n",
    "            A complex `self.dim`-dimensional vector.\n",
    "        \"\"\"\n",
    "        prod = np.ones(self.dim)\n",
    "        for mod in self._phis.values():\n",
    "            prod = self.bind(prod, mod)\n",
    "        return prod**n\n",
    "\n",
    "    def _residue_decode(self, es: List[int]) -> int:\n",
    "        \"\"\"\n",
    "        Decode a list of integers using the Chinese remainder theorem to its\n",
    "        corresponding integer.\n",
    "\n",
    "        For more information about the algorithm used, refer to Garner (1959),\n",
    "        and https://personal.utdallas.edu/~ivor/ce6305/m5p.pdf.\n",
    "\n",
    "        Returns:\n",
    "            An integer corresponding to the unique list of values provided by\n",
    "                `es`.\n",
    "        \"\"\"\n",
    "        M = int(np.prod(self.moduli))\n",
    "        x = 0\n",
    "        for i in range(len(self.moduli)):\n",
    "            m_i = self.moduli[i]\n",
    "            M_I = M // m_i\n",
    "            a_i = pow(M_I, -1, mod=m_i)\n",
    "            x += M_I * ((a_i * es[i]) % m_i)\n",
    "\n",
    "        return x % M\n",
    "\n",
    "    def gt(self, x: np.ndarray, y: np.ndarray) -> bool:\n",
    "        raise NotImplementedError(\"TODO\")\n",
    "\n",
    "    def lt(self, x: np.ndarray, y: np.ndarray) -> bool:\n",
    "        raise NotImplementedError(\"TODO\")\n",
    "\n",
    "    def _activation(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Activation function used in `decode`.\"\"\"\n",
    "        f = np.vectorize(lambda theta: theta + np.sin(theta))\n",
    "        return np.exp(cmath.sqrt(-1) * f(np.abs(x)))\n",
    "\n",
    "\n",
    "    def decode(self, x: np.ndarray, max_iterations: int = 20) -> int:\n",
    "        \"\"\"\n",
    "        Decode some `RHC` hypervector `x` into an integer using a\n",
    "        resonator network.\n",
    "        Returns:\n",
    "            An integer.\n",
    "        \"\"\"\n",
    "        factors = []\n",
    "        for modulus in self.moduli:\n",
    "            factors.append(np.sum(self._codebook[modulus], axis=1))\n",
    "\n",
    "        runs = [factors]\n",
    "        for i in range(max_iterations):\n",
    "            factors = runs[i]\n",
    "            update_factors = []\n",
    "            for j, factor in enumerate(factors):\n",
    "                codebook = self._codebook[self.moduli[j]]\n",
    "                other_factors = [\n",
    "                    other_factor\n",
    "                    for other_factor in factors\n",
    "                    if not np.array_equal(other_factor, factor)\n",
    "                ]\n",
    "\n",
    "                bins = np.ones_like(x)\n",
    "                for k, other_factor in enumerate(other_factors):\n",
    "                    bins = self.bind(bins, other_factor)\n",
    "\n",
    "                x_0 = self.bind(x, bins)\n",
    "                cleanup = np.dot(codebook, codebook.T)\n",
    "                res = self._activation(np.dot(cleanup, x_0))\n",
    "                update_factors.append(res)\n",
    "            runs.append(update_factors)\n",
    "        return runs\n",
    "\n",
    "    def vector_gen(self) -> np.ndarray:\n",
    "        raise TypeError(\n",
    "            \"TypeError: cannot just generate new RHC vectors in this implementation\"\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, key: str) -> np.ndarray:\n",
    "        return self.symbols[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity between z_3(1) and est z_3\n",
      "0.9870000000000002\n",
      "similarity between z_3(2) and est z_3\n",
      "0.9869999999999998\n",
      "similarity between z_3(3) and est z_3\n",
      "0.987\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "0.14408490013428368\n",
      "similarity between z_3(2) and est z_3\n",
      "0.15137225262819543\n",
      "similarity between z_3(3) and est z_3\n",
      "0.6915428472375229\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.1577405413693823\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.1577405413693823\n",
      "similarity between z_3(3) and est z_3\n",
      "0.8487594586306191\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "0.3127085041202072\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.17262917197429745\n",
      "similarity between z_3(3) and est z_3\n",
      "0.8469206678540919\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "0.16146796275082517\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.32386971334367937\n",
      "similarity between z_3(3) and est z_3\n",
      "0.6956801264847097\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.006500000000000055\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.006499999999999737\n",
      "similarity between z_3(3) and est z_3\n",
      "1.0\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.006500000000000055\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.006499999999999737\n",
      "similarity between z_3(3) and est z_3\n",
      "1.0\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.006500000000000055\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.006499999999999737\n",
      "similarity between z_3(3) and est z_3\n",
      "1.0\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "0.16146796275082517\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.32386971334367937\n",
      "similarity between z_3(3) and est z_3\n",
      "0.6956801264847097\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.006500000000000055\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.006499999999999737\n",
      "similarity between z_3(3) and est z_3\n",
      "1.0\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.006500000000000055\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.006499999999999737\n",
      "similarity between z_3(3) and est z_3\n",
      "1.0\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.17512360398592391\n",
      "similarity between z_3(2) and est z_3\n",
      "0.3175014246024931\n",
      "similarity between z_3(3) and est z_3\n",
      "0.8446221793834324\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.1577405413693823\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.1577405413693823\n",
      "similarity between z_3(3) and est z_3\n",
      "0.8487594586306191\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "0.3127085041202072\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.17262917197429745\n",
      "similarity between z_3(3) and est z_3\n",
      "0.8469206678540919\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "0.16146796275082517\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.32386971334367937\n",
      "similarity between z_3(3) and est z_3\n",
      "0.6956801264847097\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.006500000000000055\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.006499999999999737\n",
      "similarity between z_3(3) and est z_3\n",
      "1.0\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "0.3127085041202072\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.17262917197429745\n",
      "similarity between z_3(3) and est z_3\n",
      "0.8469206678540919\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.17512360398592391\n",
      "similarity between z_3(2) and est z_3\n",
      "0.3175014246024931\n",
      "similarity between z_3(3) and est z_3\n",
      "0.8446221793834324\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.006500000000000055\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.006499999999999737\n",
      "similarity between z_3(3) and est z_3\n",
      "1.0\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.1577405413693823\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.1577405413693823\n",
      "similarity between z_3(3) and est z_3\n",
      "0.8487594586306191\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.006500000000000055\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.006499999999999737\n",
      "similarity between z_3(3) and est z_3\n",
      "1.0\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "0.3127085041202072\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.17262917197429745\n",
      "similarity between z_3(3) and est z_3\n",
      "0.8469206678540919\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "0.3127085041202072\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.17262917197429745\n",
      "similarity between z_3(3) and est z_3\n",
      "0.8469206678540919\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.006500000000000055\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.006499999999999737\n",
      "similarity between z_3(3) and est z_3\n",
      "1.0\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.006500000000000055\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.006499999999999737\n",
      "similarity between z_3(3) and est z_3\n",
      "1.0\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.17512360398592391\n",
      "similarity between z_3(2) and est z_3\n",
      "0.3175014246024931\n",
      "similarity between z_3(3) and est z_3\n",
      "0.8446221793834324\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "0.16146796275082517\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.32386971334367937\n",
      "similarity between z_3(3) and est z_3\n",
      "0.6956801264847097\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.006500000000000055\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.006499999999999737\n",
      "similarity between z_3(3) and est z_3\n",
      "1.0\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "-0.1577405413693823\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.1577405413693823\n",
      "similarity between z_3(3) and est z_3\n",
      "0.8487594586306191\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "0.16146796275082517\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.32386971334367937\n",
      "similarity between z_3(3) and est z_3\n",
      "0.6956801264847097\n",
      "\n",
      "similarity between z_3(1) and est z_3\n",
      "0.16146796275082517\n",
      "similarity between z_3(2) and est z_3\n",
      "-0.32386971334367937\n",
      "similarity between z_3(3) and est z_3\n",
      "0.6956801264847097\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rhc = RHC(dim=1000, moduli=[3, 5, 7, 11])\n",
    "\n",
    "x2 = rhc.encode(2)\n",
    "decoded = rhc.decode(x2, max_iterations=30)\n",
    "\n",
    "for j in range(len(decoded)):\n",
    "    hat_z1 = decoded[j]\n",
    "    for i, vector in enumerate(rhc._codebook[3].T):\n",
    "        print(f\"similarity between z_3({i+1}) and est z_3\")\n",
    "        print(rhc.sim(vector, hat_z1[0]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
